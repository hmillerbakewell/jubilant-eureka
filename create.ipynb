{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating puzzle grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordnet\n",
    "\n",
    "This application will be built in top of WordNet, which will also be cited on the main page itself:\n",
    "\n",
    "Princeton University \"About WordNet.\" [WordNet](https://wordnet.princeton.edu/). Princeton University. 2010. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/hector/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/hector/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dog = wn.synsets('dog')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synset_word(synset: \"Synset\") -> str:\n",
    "    return synset.name().split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkType(Enum):\n",
    "    Synset = 1\n",
    "    Hyponym = 2\n",
    "    Hypernym = 3\n",
    "    Homonym = 4\n",
    "    Root = 5\n",
    "    Synonym = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Link:\n",
    "    synset : \"Synset\"\n",
    "    type : LinkType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step(origin: \"Synset\") -> List[Link]:\n",
    "    hypernyms = map(lambda s: Link(s, LinkType.Hypernym), origin.hypernyms())\n",
    "    hyponyms = map(lambda s: Link(s, LinkType.Hyponym), origin.hyponyms())\n",
    "    homonyms = map(lambda s: Link(s, LinkType.Homonym), wn.synsets(synset_word(origin)))\n",
    "    return list(hypernyms) + list(hyponyms) + list(homonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one_step(base_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spoof class for type checking\n",
    "class Synset:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Path:\n",
    "    origin: \"Synset\"\n",
    "    links: List[Link]\n",
    "\n",
    "    @property\n",
    "    def synset(self):\n",
    "        assert len(self.links) > 0\n",
    "        return self.links[-1].synset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ball(origin_synset: \"Synset\", distance: int):\n",
    "    origin_points = [Path(origin_synset, [Link(origin_synset, LinkType.Root)])]\n",
    "    synsets_so_far: List[Synset] = [path.synset for path in origin_points]\n",
    "    paths_so_far: List[Path] = [point for point in origin_points]\n",
    "    outer_shell: List[Path] = [point for point in origin_points]\n",
    "    for i in range(distance):\n",
    "        next_outer_shell: List[Path] = []\n",
    "        for point in outer_shell:\n",
    "            novel_steps: List[Link] = [step for step in one_step(point.synset)\n",
    "                                       if step.synset not in synsets_so_far]\n",
    "            accepted_points: List[Path] = [Path(origin_synset, [link for link in point.links] + [p])\n",
    "                                           for p in novel_steps]\n",
    "            for new_point in accepted_points:\n",
    "                paths_so_far.append(new_point)\n",
    "                synsets_so_far.append(new_point.synset)\n",
    "                next_outer_shell.append(new_point)\n",
    "        outer_shell = [point for point in next_outer_shell]\n",
    "    return paths_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spheres(origin_word: str, distance: int) -> List[List[Path]]:\n",
    "    all = ball(origin_word, distance)\n",
    "    spheres = []\n",
    "    for i in range(1, distance+1):\n",
    "        spheres.append([path for path in all if len(path.links) == i])\n",
    "    return spheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def rfrom(_list):\n",
    "    return _list[int(random.random() * len(_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_synset_for(word: str):\n",
    "    synsets = wn.synsets(word)\n",
    "    return rfrom(synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Path(origin=Synset('hat.v.02'), links=[Link(synset=Synset('hat.v.02'), type=<LinkType.Root: 5>)])],\n",
       " [Path(origin=Synset('hat.v.02'), links=[Link(synset=Synset('hat.v.02'), type=<LinkType.Root: 5>), Link(synset=Synset('supply.v.01'), type=<LinkType.Hypernym: 3>)]),\n",
       "  Path(origin=Synset('hat.v.02'), links=[Link(synset=Synset('hat.v.02'), type=<LinkType.Root: 5>), Link(synset=Synset('hat.n.01'), type=<LinkType.Homonym: 4>)]),\n",
       "  Path(origin=Synset('hat.v.02'), links=[Link(synset=Synset('hat.v.02'), type=<LinkType.Root: 5>), Link(synset=Synset('hat.n.02'), type=<LinkType.Homonym: 4>)]),\n",
       "  Path(origin=Synset('hat.v.02'), links=[Link(synset=Synset('hat.v.02'), type=<LinkType.Root: 5>), Link(synset=Synset('hat.v.01'), type=<LinkType.Homonym: 4>)])]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spheres(random_synset_for(\"hat\"), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making games out of this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Center word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea: Select the correct center word from a list of nine words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read in the list of common words. The correct answer should be inside this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def read_moby():\n",
    "    path=\"moby-common.txt\"\n",
    "    restriction = r\"(\\W|\\.|-|\\d|[A-Z])\"\n",
    "    with open(path, \"r\") as file:\n",
    "        words_with_linebreak = file.readlines()\n",
    "    words_with_bad_characters = [word.replace(\"\\n\",\"\") for word in words_with_linebreak]\n",
    "    no_bad_characters = [word for word in words_with_bad_characters if re.search(restriction, word) is None]\n",
    "    right_length = [word for word in no_bad_characters if len(word) in range(3,8)]\n",
    "    return right_length\n",
    "\n",
    "common_words = read_moby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_synset_get_spheres(synset: \"Synset\"):\n",
    "    try:\n",
    "        word_spheres = spheres(synset,3)\n",
    "        return word_spheres\n",
    "    except Exception as e:\n",
    "        print(f\"Rejecting {synset}: uncaught exception {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we display to the player?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CWPlayerOption:\n",
    "    word: str\n",
    "    path: Path\n",
    "    description: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define(synset: \"Synset\"):\n",
    "    return f\"{synset_word(synset)}: {synset.definition()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't accept qualified synsets (ones with spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept_synset(synset: \"Synset\") -> bool:\n",
    "    word = synset_word(synset)\n",
    "    if \"_\" in word:\n",
    "        return False\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept_path(path: Path) -> bool:\n",
    "    return all(map(lambda link: accept_synset(link.synset), path.links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the chain human readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_description(path: Path):\n",
    "    base = \"\"\n",
    "    connectors = {\n",
    "        LinkType.Synset: \"\",\n",
    "        LinkType.Homonym: \" -(alternate meaning)-> \",\n",
    "        LinkType.Hypernym: \" -(an example of)-> \",\n",
    "        LinkType.Hyponym: \" -(an example being)-> \",\n",
    "        LinkType.Root: \"\",\n",
    "        LinkType.Synonym: \" -(synonymous with)-> \",\n",
    "    }\n",
    "    for link in path.links:\n",
    "        base += connectors[link.type]\n",
    "        base += define(link.synset)\n",
    "    return base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want the words to be distinct enough to avoid, e.g. \"live\" and \"alive\" being in the grid together.\n",
    "Use fuzzy matching to discriminate against words similar to words already accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/f/github/personal/spiderweb/.venv/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import fuzzywuzzy\n",
    "import fuzzywuzzy.fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid needs to have a unique solution,\n",
    "so that all other words are within distance 2 of the target,\n",
    "and so that the words in the grid are path-connected using just those words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cw_game(synset: \"Synset\"):\n",
    "    word_spheres = assess_synset_get_spheres(synset)\n",
    "    if word_spheres is None:\n",
    "        return None\n",
    "    distant: List[Path] = [\n",
    "        path for path in word_spheres[2] if accept_path(path)]\n",
    "    near: List[Path] = [path for path in word_spheres[1] if accept_path(path)]\n",
    "    random.shuffle(distant)\n",
    "    random.shuffle(near)\n",
    "\n",
    "    origin = Path(synset, [Link(synset, LinkType.Root)])\n",
    "\n",
    "    chosen_far: List[CWPlayerOption] = []\n",
    "    chosen_near: List[CWPlayerOption] = []\n",
    "    words_used: List[str] = [synset_word(synset)]\n",
    "\n",
    "    allowed_ratio = 80\n",
    "\n",
    "    def similar_word_used(word: str):\n",
    "        ratios = [fuzzywuzzy.fuzz.ratio(word, existing_word)\n",
    "                  for existing_word in words_used]\n",
    "        return max(ratios) > allowed_ratio\n",
    "\n",
    "    while len(chosen_far + chosen_near) < 7 and len(distant) > 0:\n",
    "        path = distant.pop()\n",
    "        word = synset_word(path.synset)\n",
    "        bridge_word = synset_word(path.links[1].synset)\n",
    "        bridge_path = Path(path.origin, path.links[:-1])\n",
    "\n",
    "        ratio = fuzzywuzzy.fuzz.ratio(word, bridge_word)\n",
    "\n",
    "        if not ratio > allowed_ratio:\n",
    "            near_already_exists = path_to_description(bridge_path) in [\n",
    "                path_to_description(option.path) for option in chosen_near]\n",
    "\n",
    "            if not similar_word_used(word):\n",
    "                if near_already_exists:\n",
    "                    chosen_far.append(CWPlayerOption(\n",
    "                        word, path, path_to_description(path)))\n",
    "                    words_used.append(word)\n",
    "                else:\n",
    "                    if not similar_word_used(bridge_word):\n",
    "                        if not word == bridge_word:\n",
    "                            chosen_far.append(CWPlayerOption(\n",
    "                                word, path, path_to_description(path)))\n",
    "                            chosen_near.append(CWPlayerOption(\n",
    "                                bridge_word, bridge_path, path_to_description(bridge_path)))\n",
    "                            words_used.append(word)\n",
    "                            words_used.append(bridge_word)\n",
    "\n",
    "    if len(chosen_near) < 2:\n",
    "        # Need a path of length 5 to have a hope of determining the center\n",
    "        return None\n",
    "\n",
    "    while len(chosen_far + chosen_near) < 8 and len(near) > 0:\n",
    "        path = near.pop()\n",
    "        word = synset_word(path.synset)\n",
    "        if word not in words_used:\n",
    "            chosen_near.append(CWPlayerOption(\n",
    "                word, path, path_to_description(path)))\n",
    "            words_used.append(word)\n",
    "\n",
    "    # Need unique right answer\n",
    "    # Each wrong answer needs at least one word that is distance > 2 from it\n",
    "    for answer in chosen_far + chosen_near:\n",
    "        for potential_target_synset in wn.synsets(answer.word):\n",
    "            ball_around_option = assess_synset_get_spheres(potential_target_synset)\n",
    "            words_within_two = [synset_word(\n",
    "                path.synset) for layer in ball_around_option for path in layer]\n",
    "            if all([word in words_within_two for word in words_used]):\n",
    "                return None\n",
    "\n",
    "    return chosen_far + chosen_near + [CWPlayerOption(synset_word(synset), origin, path_to_description(origin))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A game is really just 9 options, one of which is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_cw_game(random_synset_for(\"shape\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the player will see (randomised, so may need to run a few times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = build_cw_game(random_synset_for(\"shape\"))\n",
    "if game is not None:\n",
    "    for option in game:\n",
    "        print(option.word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's sample a large number of acceptable target words, and build webs around those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_common_words = [rfrom(common_words) for _ in range(100000)]\n",
    "cw_games : List[List[CWPlayerOption]] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximately 10% of starting words lead to a valid game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_or_none(word: str) -> Optional[\"game\"]:\n",
    "    try:\n",
    "        for synset in wn.synsets(word):\n",
    "            if synset_word(synset) == word:\n",
    "                game = build_cw_game(synset)\n",
    "                if game is not None:\n",
    "                    if len(game) == 9:\n",
    "                        return game\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [47:34<00:00,  2.85s/it] \n"
     ]
    }
   ],
   "source": [
    "for word in tqdm(selected_common_words[1000:2000]):\n",
    "    game = get_game_or_none(word)\n",
    "    if game is not None:\n",
    "        cw_games.append(game)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cw_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_mock_board(list_of_options: List[CWPlayerOption]):\n",
    "    for option in list_of_options:\n",
    "        print(option.word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "communicate\n",
      "frown\n",
      "wince\n",
      "squint\n",
      "fleer\n",
      "grimace\n",
      "smirk\n",
      "grin\n",
      "smile\n"
     ]
    }
   ],
   "source": [
    "cw_mock_board(cw_games[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This all needs to be stored as JSON so it can be read by the javascript frontend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_compress_option(option: CWPlayerOption)-> Dict[str, Any]:\n",
    "    return {\"s\": 3-len(option.path.links), \"w\": option.word, \"d\": option.description}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_compress_game(game) -> List[Dict[str, Any]]:\n",
    "    return list(map(cw_compress_option, game))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some basic checks are made:\n",
    " - profanity\n",
    " - enough distance-2 words\n",
    " - enough words are in our list of common words\n",
    " - words aren't too short (the letter \"c\" was once  a suggested word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cw_restrict_games(games_list: List[\"game\"]) -> List[\"game\"]:\n",
    "    # The following words came up in tests\n",
    "    # And I want to exclude games that use them\n",
    "\n",
    "    blocked_words = [\"derogatory\", \"insult\", \"insulting\",\n",
    "                     \"whore\", \"pimp\", \"fuck\", \"obscene\", \"shit\"]\n",
    "\n",
    "    def pass_option(option: CWPlayerOption) -> bool:\n",
    "        # Simple word filter\n",
    "        words_used = re.split(\"\\W\", option.description)\n",
    "        return all([word not in words_used for word in blocked_words])\n",
    "\n",
    "    def pass_game(game: List[CWPlayerOption]) -> bool:\n",
    "        # Check the shortest word is at least 3 letters\n",
    "        shortest = min([len(option.word) for option in game])\n",
    "        if shortest < 3:\n",
    "            return False\n",
    "        # Check there is at least two paths of length 2\n",
    "        furthest = sum([len(option.path.links) == 3 for option in game])\n",
    "        if furthest < 1:\n",
    "            return False\n",
    "        # Check at least 3 words are in the list of common words\n",
    "        count_common = sum(\n",
    "            [1 for option in game if option.word in common_words])\n",
    "        if count_common < 3:\n",
    "            return False\n",
    "        # Check the individual options are allowed\n",
    "        return all([pass_option(option) for option in game])\n",
    "    return [game for game in games_list if pass_game(game)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many does that leave us with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cw_restrict_games(cw_games))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"webs.json\", \"w\") as file:\n",
    "    json.dump(list(map(cw_compress_game, cw_restrict_games(cw_games))), file)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c77213bcb2b0b038aabc36a451f11307abe3b2b13a86c30a6d1526ddfdcb9c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
